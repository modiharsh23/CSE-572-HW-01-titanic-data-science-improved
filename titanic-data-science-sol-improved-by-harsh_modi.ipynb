{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a1b2c3d4",
            "metadata": {},
            "source": [
                "## Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "dc3c136b",
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "\n",
                "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.svm import SVC, LinearSVC\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "from sklearn.metrics import accuracy_score\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5f6g7h8",
            "metadata": {},
            "source": [
                "## Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "c6a26488",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data = pd.read_csv(\"Data/train.csv\")\n",
                "test_data = pd.read_csv(\"Data/test.csv\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "i9j0k1l2",
            "metadata": {},
            "source": [
                "## Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "b49dab3a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_title(name: str) -> str:\n",
                "    match = re.search(r\",\\s*([^\\.]+)\\.\", name)\n",
                "    return match.group(1).strip() if match else \"Unknown\"\n",
                "\n",
                "def build_features(data: pd.DataFrame) -> pd.DataFrame:\n",
                "    data = data.copy()\n",
                "\n",
                "    data[\"Title\"] = data[\"Name\"].apply(get_title)\n",
                "\n",
                "    replacements = {\n",
                "        \"Mlle\": \"Miss\",\n",
                "        \"Ms\": \"Miss\",\n",
                "        \"Mme\": \"Mrs\",\n",
                "        \"Lady\": \"Rare\",\n",
                "        \"Countess\": \"Rare\",\n",
                "        \"Capt\": \"Rare\",\n",
                "        \"Col\": \"Rare\",\n",
                "        \"Don\": \"Rare\",\n",
                "        \"Dr\": \"Rare\",\n",
                "        \"Major\": \"Rare\",\n",
                "        \"Rev\": \"Rare\",\n",
                "        \"Sir\": \"Rare\",\n",
                "        \"Jonkheer\": \"Rare\",\n",
                "        \"Dona\": \"Rare\",\n",
                "    }\n",
                "    data[\"Title\"] = data[\"Title\"].replace(replacements)\n",
                "\n",
                "    data[\"FamilySize\"] = data[\"SibSp\"] + data[\"Parch\"] + 1\n",
                "    data[\"IsAlone\"] = (data[\"FamilySize\"] == 1).astype(int)\n",
                "\n",
                "    data[\"HasCabin\"] = data[\"Cabin\"].notna().astype(int)\n",
                "\n",
                "    data[\"TicketGroupSize\"] = data.groupby(\"Ticket\")[\"Ticket\"].transform(\"count\")\n",
                "\n",
                "    return data\n",
                "\n",
                "train_data = build_features(train_data)\n",
                "test_data = build_features(test_data)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "m3n4o5p6",
            "metadata": {},
            "source": [
                "## Target and Feature Selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "871cf61b",
            "metadata": {},
            "outputs": [],
            "source": [
                "y_train = train_data[\"Survived\"].astype(int)\n",
                "\n",
                "cols_to_drop = [\"Survived\", \"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"]\n",
                "x_train = train_data.drop(columns=cols_to_drop)\n",
                "x_test = test_data.drop(columns=[\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "q7r8s9t0",
            "metadata": {},
            "source": [
                "## Missing Value Imputation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "0d3351c6",
            "metadata": {},
            "outputs": [],
            "source": [
                "def fill_missing_age(data: pd.DataFrame) -> pd.DataFrame:\n",
                "    data = data.copy()\n",
                "    medians = data.groupby([\"Sex\", \"Pclass\"])[\"Age\"].median()\n",
                "\n",
                "    def age_filler(row):\n",
                "        if pd.notna(row[\"Age\"]):\n",
                "            return row[\"Age\"]\n",
                "        return medians.loc[(row[\"Sex\"], row[\"Pclass\"])]\n",
                "\n",
                "    data[\"Age\"] = data.apply(age_filler, axis=1)\n",
                "    return data\n",
                "\n",
                "x_train = fill_missing_age(x_train)\n",
                "x_test = fill_missing_age(x_test)\n",
                "\n",
                "x_train[\"Fare\"] = x_train[\"Fare\"].fillna(x_train[\"Fare\"].median())\n",
                "x_test[\"Fare\"] = x_test[\"Fare\"].fillna(x_test[\"Fare\"].median())\n",
                "\n",
                "x_train[\"Fare\"] = np.log1p(x_train[\"Fare\"])\n",
                "x_test[\"Fare\"] = np.log1p(x_test[\"Fare\"])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "u1v2w3x4",
            "metadata": {},
            "source": [
                "## Preprocessing Pipelines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "70b7dd26",
            "metadata": {},
            "outputs": [],
            "source": [
                "num_cols = [\"Age\", \"Fare\", \"SibSp\", \"Parch\", \"FamilySize\", \"IsAlone\", \"HasCabin\", \"TicketGroupSize\"]\n",
                "cat_cols = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\"]\n",
                "\n",
                "num_pipe = Pipeline(steps=[\n",
                "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
                "    (\"scaler\", StandardScaler())\n",
                "])\n",
                "\n",
                "num_pipe_raw = Pipeline(steps=[\n",
                "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
                "])\n",
                "\n",
                "cat_pipe = Pipeline(steps=[\n",
                "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
                "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
                "])\n",
                "\n",
                "pre_scaled = ColumnTransformer(\n",
                "    transformers=[\n",
                "        (\"num\", num_pipe, num_cols),\n",
                "        (\"cat\", cat_pipe, cat_cols),\n",
                "    ],\n",
                "    remainder=\"drop\"\n",
                ")\n",
                "\n",
                "pre_basic = ColumnTransformer(\n",
                "    transformers=[\n",
                "        (\"num\", num_pipe_raw, num_cols),\n",
                "        (\"cat\", cat_pipe, cat_cols),\n",
                "    ],\n",
                "    remainder=\"drop\"\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "y5z6a7b8",
            "metadata": {},
            "source": [
                "## Model Definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "81058bbf",
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {\n",
                "    \"Support Vector Machines\": (SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42), pre_scaled),\n",
                "    \"KNN\": (KNeighborsClassifier(n_neighbors=5), pre_scaled),\n",
                "    \"Logistic Regression\": (LogisticRegression(max_iter=2000, random_state=42), pre_scaled),\n",
                "    \"Random Forest\": (RandomForestClassifier(n_estimators=300, random_state=42), pre_basic),\n",
                "    \"Naive Bayes\": (GaussianNB(), pre_basic),\n",
                "    \"Perceptron\": (Perceptron(random_state=42), pre_scaled),\n",
                "    \"Stochastic Gradient Decent\": (SGDClassifier(loss=\"hinge\", random_state=42), pre_scaled),\n",
                "    \"Linear SVC\": (LinearSVC(max_iter=2000, random_state=42), pre_scaled),\n",
                "    \"Decision Tree\": (DecisionTreeClassifier(random_state=42), pre_basic),\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c9d0e1f2",
            "metadata": {},
            "source": [
                "## Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "15f5db76",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                     Model  Kaggle Score (%)  Improved Score (%)\n",
                        "             Random Forest             86.76               98.65\n",
                        "             Decision Tree             86.76               98.65\n",
                        "                       KNN             84.85               85.86\n",
                        "   Support Vector Machines             78.23               84.18\n",
                        "                Linear SVC             78.90               83.50\n",
                        "       Logistic Regression             80.36               83.28\n",
                        "Stochastic Gradient Decent             74.86               83.05\n",
                        "               Naive Bayes             72.28               82.49\n",
                        "                Perceptron             78.34               72.50\n"
                    ]
                }
            ],
            "source": [
                "kaggle_scores = {\n",
                "    \"Random Forest\": 86.76,\n",
                "    \"Decision Tree\": 86.76,\n",
                "    \"KNN\": 84.85,\n",
                "    \"Logistic Regression\": 80.36,\n",
                "    \"Linear SVC\": 78.90,\n",
                "    \"Perceptron\": 78.34,\n",
                "    \"Support Vector Machines\": 78.23,\n",
                "    \"Stochastic Gradient Decent\": 74.86,\n",
                "    \"Naive Bayes\": 72.28,\n",
                "}\n",
                "\n",
                "results = []\n",
                "\n",
                "for name, (clf, prep) in models.items():\n",
                "    pipe = Pipeline(steps=[\n",
                "        (\"preprocess\", prep),\n",
                "        (\"model\", clf)\n",
                "    ])\n",
                "\n",
                "    if name == \"Naive Bayes\":\n",
                "        tr = prep.fit_transform(x_train)\n",
                "        if hasattr(tr, \"toarray\"):\n",
                "            tr = tr.toarray()\n",
                "        clf.fit(tr, y_train)\n",
                "        score = round(clf.score(tr, y_train) * 100, 2)\n",
                "    else:\n",
                "        pipe.fit(x_train, y_train)\n",
                "        score = round(pipe.score(x_train, y_train) * 100, 2)\n",
                "\n",
                "    baseline = kaggle_scores[name]\n",
                "    results.append((name, baseline, score))\n",
                "\n",
                "results_df = pd.DataFrame(results, columns=[\"Model\", \"Kaggle Score (%)\", \"Improved Score (%)\"]).sort_values(\n",
                "    by=\"Improved Score (%)\", ascending=False\n",
                ")\n",
                "\n",
                "print(results_df.to_string(index=False))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}